{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full extraction for RGB + NDVI patches using polygon annotations.\n",
    "\n",
    "Pass 1: geometry-only classification (fast; no raster IO) over full extent\n",
    "Pass 2: read+save selected windows into dataset_{k}/{label}/...\n",
    "\n",
    "Requires:\n",
    "  pip install rasterio geopandas shapely numpy pillow rtree\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.vrt import WarpedVRT\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "NDVI_PATH = r\"path/to/orthomosaic_ndvi.tif\"\n",
    "RGB_PATH = r\"/path/to/orthomosaic_rgb.tif\"\n",
    "GEOJSON  = r\"/path/to/annotations.geojson\"\n",
    "OUT_ROOT = r\"/path/to/OUT_ROOT\"\n",
    "\n",
    "SAVE_FORMAT = \"both\"   # 'png' | 'npy' | 'both'\n",
    "PNG_SCALE_PER_PATCH = True\n",
    "\n",
    "PATCH_SIZE = 224\n",
    "STRIDE     = 128\n",
    "MIN_VALID  = 0.5   # min fraction of valid pixels (across all rasters)\n",
    "MIN_COVER_FRAC = 0.05  # min fraction of tile covered by annotations to be positive\n",
    "LABEL_FIELD  = \"Class\"  # in GeoJSON: \"High Risk\", \"Medium Risk\", \"No Risk\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "RESAMPLING_METHOD = Resampling.bilinear\n",
    "\n",
    "RASTER_STACK = [RGB_PATH, NDVI_PATH]\n",
    "\n",
    "# size of the spatial blocks that define each dataset_k\n",
    "BLOCK_SIZE = 2048  # adjust as you like\n",
    "\n",
    "# Treat pure-black RGB pixels as nodata (for black borders with no nodata flag)\n",
    "TREAT_ZERO_AS_NODATA = True\n",
    "BLACK_THRESHOLD = 0   # 0 for exact black; set to 1–2 if there are near-black halos\n",
    "\n",
    "EDGE_FRAC = 0.95   # require ≥95% valid pixels to call it “inside”\n",
    "\n",
    "# ---------- LIGHT LOGGING & VALIDATION HELPERS ----------\n",
    "def log(msg: str):\n",
    "    print(f\"[INFO] {msg}\", flush=True)\n",
    "\n",
    "def validate_config():\n",
    "    for p in [RGB_PATH, NDVI_PATH, GEOJSON]:\n",
    "        assert Path(p).exists(), f\"Missing file: {p}\"\n",
    "    assert isinstance(PATCH_SIZE, int) and PATCH_SIZE > 0\n",
    "    assert isinstance(STRIDE, int) and STRIDE > 0\n",
    "    assert 0.0 <= MIN_VALID <= 1.0\n",
    "\n",
    "def assert_raster_profile(profile: dict):\n",
    "    assert profile.get(\"crs\") is not None\n",
    "    for k in [\"transform\", \"width\", \"height\"]:\n",
    "        assert k in profile\n",
    "    assert profile[\"width\"] > 0 and profile[\"height\"] > 0\n",
    "\n",
    "def assert_gdf(gdf: gpd.GeoDataFrame):\n",
    "    if len(gdf) > 0:\n",
    "        assert gdf.crs is not None\n",
    "        assert LABEL_FIELD in gdf.columns, (\n",
    "            f\"LABEL_FIELD '{LABEL_FIELD}' not in annotation columns: {list(gdf.columns)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ===================== UTILITIES =====================\n",
    "def load_reference_profile(ref_path: str) -> dict:\n",
    "    with rasterio.open(ref_path) as ref:\n",
    "        return {\n",
    "            \"crs\": ref.crs,\n",
    "            \"transform\": ref.transform,\n",
    "            \"width\": ref.width,\n",
    "            \"height\": ref.height,\n",
    "        }\n",
    "\n",
    "def load_annotations(geojson_path: str, target_crs) -> gpd.GeoDataFrame:\n",
    "    gdf = gpd.read_file(geojson_path)\n",
    "    if gdf.crs != target_crs:\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "    return gdf\n",
    "\n",
    "def build_grid(width: int, height: int, patch: int, stride: int) -> list[tuple[int, int]]:\n",
    "    xs = list(range(0, max(0, width  - patch + 1), stride))\n",
    "    ys = list(range(0, max(0, height - patch + 1), stride))\n",
    "    return [(x, y) for y in ys for x in xs]\n",
    "\n",
    "def window_bbox(ref_ds, win: Window) -> tuple[float, float, float, float]:\n",
    "    w_transform = ref_ds.window_transform(win)\n",
    "    left,  top    = w_transform * (0, 0)\n",
    "    right, bottom = w_transform * (win.width, win.height)\n",
    "    return left, bottom, right, top\n",
    "\n",
    "# ---------- skip nodata/black windows ----------\n",
    "def window_has_data(ref_ds, win: Window) -> bool:\n",
    "    \"\"\"\n",
    "    True if the window contains any real data.\n",
    "    1) Mask says at least one valid pixel.\n",
    "    2) If enabled, RGB sniff: require at least one pixel > BLACK_THRESHOLD.\n",
    "    \"\"\"\n",
    "    m = ref_ds.read_masks(1, window=win)            # 0 = nodata, >0 = valid\n",
    "    if not np.any(m):\n",
    "        return False\n",
    "\n",
    "    if TREAT_ZERO_AS_NODATA:\n",
    "        bands_to_read = min(3, ref_ds.count)        # up to first 3 bands (RGB)\n",
    "        rgb = ref_ds.read(\n",
    "            indexes=list(range(1, bands_to_read + 1)),\n",
    "            window=win,\n",
    "            masked=False\n",
    "        )  # (bands,H,W)\n",
    "        if not np.any(rgb > BLACK_THRESHOLD):\n",
    "            print(\"warning: window rejected due to all-black RGB\")\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def classify_overlap_label(bbox_poly, gdf, sindex, min_cover_frac: float = 0.05) -> tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Returns (label, frac_covered).\n",
    "\n",
    "    Tiles with total coverage < min_cover_frac are 'No Risk'.\n",
    "    Any overlap with High or Medium risk polygons -> 'Risk'.\n",
    "    Otherwise -> 'No Risk'.\n",
    "    \"\"\"\n",
    "    if sindex is None:\n",
    "        return \"No Risk\", 0.0\n",
    "\n",
    "    cand_idx = list(sindex.intersection(bbox_poly.bounds))\n",
    "    if not cand_idx:\n",
    "        return \"No Risk\", 0.0\n",
    "\n",
    "    hits = gdf.iloc[cand_idx]\n",
    "    inter = hits.geometry.intersection(bbox_poly)\n",
    "\n",
    "    areas = np.array(\n",
    "        [g.area if (g is not None and not g.is_empty) else 0.0 for g in inter],\n",
    "        dtype=float,\n",
    "    )\n",
    "    tile_area = bbox_poly.area if bbox_poly.area > 0 else 0.0\n",
    "    frac_total = float(areas.sum()) / tile_area if tile_area > 0 else 0.0\n",
    "\n",
    "    # If too little overlap overall, treat as negative\n",
    "    if frac_total < min_cover_frac:\n",
    "        return \"No Risk\", frac_total\n",
    "\n",
    "    labels_norm = hits[LABEL_FIELD].astype(str).str.lower().tolist()\n",
    "\n",
    "    has_risk = any(\n",
    "        (l.startswith(\"high\") or l.startswith(\"medium\")) and areas[i] > 0\n",
    "        for i, l in enumerate(labels_norm)\n",
    "    )\n",
    "\n",
    "    if has_risk:\n",
    "        return \"Risk\", frac_total\n",
    "    else:\n",
    "        return \"No Risk\", frac_total\n",
    "\n",
    "\n",
    "\n",
    "def read_window_stack_aligned(raster_paths: list[str], window: Window, ref_profile: dict):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      stacked: (C,H,W)  (masked pixels filled with 0)\n",
    "      valid_mask: (H,W) bool (AND of dataset masks read via read_masks)\n",
    "    \"\"\"\n",
    "    chans, masks = [], []\n",
    "\n",
    "    for i, rp in enumerate(raster_paths):\n",
    "        with rasterio.open(rp) as src:\n",
    "            if i == 0:\n",
    "                # Reference (RGB) on native grid\n",
    "                arr = src.read(window=window, masked=True)          # (B,H,W) masked\n",
    "                chans.append(np.ma.filled(arr, 0))\n",
    "                m = src.read_masks(1, window=window) > 0            # (H,W) True=valid\n",
    "                masks.append(m)\n",
    "            else:\n",
    "                # Align others onto reference grid\n",
    "                with WarpedVRT(\n",
    "                    src,\n",
    "                    crs=ref_profile[\"crs\"],\n",
    "                    transform=ref_profile[\"transform\"],\n",
    "                    width=ref_profile[\"width\"],\n",
    "                    height=ref_profile[\"height\"],\n",
    "                    resampling=RESAMPLING_METHOD,\n",
    "                ) as vrt:\n",
    "                    arr = vrt.read(window=window, masked=True)      # (B,H,W)\n",
    "                    chans.append(np.ma.filled(arr, 0))\n",
    "                    m = vrt.read_masks(1, window=window) > 0        # (H,W) True=valid\n",
    "                    masks.append(m)\n",
    "\n",
    "    stacked = np.concatenate(chans, axis=0)                         # (C,H,W)\n",
    "    valid_mask = np.logical_and.reduce(masks)                       # (H,W)\n",
    "    return stacked, valid_mask\n",
    "\n",
    "\n",
    "def to_uint8_per_patch(img_hw_c: np.ndarray) -> np.ndarray:\n",
    "    H, W, C = img_hw_c.shape\n",
    "    out = np.zeros((H, W, C), dtype=np.uint8)\n",
    "    for b in range(C):\n",
    "        band = img_hw_c[:, :, b].astype(np.float32)\n",
    "        mn, mx = np.nanmin(band), np.nanmax(band)\n",
    "        out[:, :, b] = 0 if (not np.isfinite(mn) or not np.isfinite(mx) or mx == mn) \\\n",
    "            else np.clip((band - mn) / (mx - mn) * 255.0, 0, 255).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------- margin filter and grouping into blocks ----------\n",
    "def margin_filter_meta(meta, block_size: int, patch_size: int, stride: int):\n",
    "    halo = max(0, patch_size - stride)\n",
    "    if halo == 0:\n",
    "        return meta\n",
    "    kept = []\n",
    "    for m in meta:\n",
    "        x, y = m[\"x\"], m[\"y\"]\n",
    "        bx = (x // block_size) * block_size\n",
    "        by = (y // block_size) * block_size\n",
    "        left_gap   = x - bx\n",
    "        top_gap    = y - by\n",
    "        right_gap  = (bx + block_size) - (x + patch_size)\n",
    "        bottom_gap = (by + block_size) - (y + patch_size)\n",
    "        if min(left_gap, top_gap, right_gap, bottom_gap) >= halo:\n",
    "            kept.append(m)\n",
    "    return kept\n",
    "\n",
    "\n",
    "def group_into_blocks(\n",
    "    meta,\n",
    "    *,\n",
    "    block_size: int,\n",
    "    patch_size: int,\n",
    "    stride: int,\n",
    "    apply_margin_filter: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Group patches in `meta` into spatial blocks of size `block_size x block_size`.\n",
    "\n",
    "    Returns:\n",
    "      block_groups: dict[int, list[int]]\n",
    "          block_id -> list of indices into meta_kept\n",
    "      unique_groups: np.ndarray of shape (n_blocks, 2)\n",
    "          each row is [gx, gy] block-grid coordinate\n",
    "      meta_kept: list[dict]\n",
    "          filtered meta (after optional margin filter)\n",
    "    \"\"\"\n",
    "    meta_kept = margin_filter_meta(meta, block_size, patch_size, stride) if apply_margin_filter else meta\n",
    "\n",
    "    xs = np.array([m[\"x\"] for m in meta_kept])\n",
    "    ys = np.array([m[\"y\"] for m in meta_kept])\n",
    "\n",
    "    # block grid coordinates (integer)\n",
    "    groups_xy = np.column_stack([xs // block_size, ys // block_size])  # (N, 2)\n",
    "    unique_groups, inv = np.unique(groups_xy, axis=0, return_inverse=True)\n",
    "\n",
    "    block_groups: dict[int, list[int]] = defaultdict(list)\n",
    "    for idx_meta, block_id in enumerate(inv):\n",
    "        block_groups[int(block_id)].append(idx_meta)\n",
    "\n",
    "    print(f\"{len(unique_groups)} block-datasets created.\")\n",
    "    return block_groups, unique_groups, meta_kept\n",
    "\n",
    "\n",
    "def save_patch_png_and_or_npy(base_path: Path, img_hwc: np.ndarray, save_format: str, scale_per_patch=True) -> str:\n",
    "    saved_name = None\n",
    "    if save_format in (\"png\", \"both\") and img_hwc.shape[2] <= 4:\n",
    "        img8 = to_uint8_per_patch(img_hwc) if scale_per_patch else (\n",
    "            img_hwc / max(1e-9, np.nanmax(img_hwc)) * 255\n",
    "        ).astype(np.uint8)\n",
    "        Image.fromarray(img8).save(base_path.with_suffix(\".png\"))\n",
    "        saved_name = base_path.with_suffix(\".png\").name\n",
    "    if save_format in (\"npy\", \"both\"):\n",
    "        np.save(str(base_path.with_suffix(\".npy\")), img_hwc)\n",
    "        if saved_name is None:\n",
    "            saved_name = base_path.with_suffix(\".npy\").name\n",
    "    return saved_name\n",
    "\n",
    "def write_csv_header(csv_writer):\n",
    "    csv_writer.writerow([\n",
    "        \"set\",\"filename\",\"label\",\"frac_covered\",\n",
    "        \"xmin\",\"ymin\",\"xmax\",\"ymax\",\"center_x\",\"center_y\",\n",
    "        \"x_pix\",\"y_pix\",\"patch_size\",\n",
    "        \"src_rgb\",\"src_ndvi\"\n",
    "    ])\n",
    "\n",
    "def csv_row_for_meta(set_name, saved_name, m, patch_size, rgb_name, ndvi_name):\n",
    "    cx = (m[\"left\"] + m[\"right\"]) / 2.0\n",
    "    cy = (m[\"bottom\"] + m[\"top\"]) / 2.0\n",
    "    return [\n",
    "        set_name, saved_name, m[\"label\"], f\"{m['frac']:.6f}\",\n",
    "        m[\"left\"], m[\"bottom\"], m[\"right\"], m[\"top\"], cx, cy,\n",
    "        m[\"x\"], m[\"y\"], patch_size,\n",
    "        rgb_name, ndvi_name\n",
    "    ]\n",
    "\n",
    "\n",
    "# ===================== DYNAMIC EDGE BUFFERS =====================\n",
    "\n",
    "def compute_edges_95(ref_path: str, frac: float = 0.95, black_thr: int = 0, use_bands: int = 3):\n",
    "    \"\"\"\n",
    "    Dynamic edge detector using 'black==nodata':\n",
    "      Valid(x,y) = any( band_value > black_thr ) across first `use_bands` bands.\n",
    "    Finds first col/row where valid-fraction >= frac.\n",
    "    Returns pixel offsets: left, right, top, bottom.\n",
    "    \"\"\"\n",
    "    with rasterio.open(ref_path) as ds:\n",
    "        H, W = ds.height, ds.width\n",
    "        b = min(use_bands, ds.count)\n",
    "        if b == 0:\n",
    "            raise ValueError(\"Raster has no bands.\")\n",
    "\n",
    "        # Build black-is-nodata mask: (H, W) bool\n",
    "        rgb = ds.read(indexes=list(range(1, b+1)), masked=False)  # (b,H,W)\n",
    "        mask = np.any(rgb > black_thr, axis=0)\n",
    "\n",
    "        # Column-wise (over all rows)\n",
    "        col_frac = mask.mean(axis=0)\n",
    "        left  = int(np.argmax(col_frac >= frac))  if np.any(col_frac >= frac)  else W\n",
    "        right = int(np.argmax(col_frac[::-1] >= frac)) if np.any(col_frac[::-1] >= frac) else W\n",
    "\n",
    "        # Row-wise (over all cols)\n",
    "        row_frac = mask.mean(axis=1)\n",
    "        top    = int(np.argmax(row_frac >= frac))  if np.any(row_frac >= frac)  else H\n",
    "        bottom = int(np.argmax(row_frac[::-1] >= frac)) if np.any(row_frac[::-1] >= frac) else H\n",
    "\n",
    "    return {\"left\": left, \"right\": right, \"top\": top, \"bottom\": bottom}\n",
    "\n",
    "\n",
    "\n",
    "# ===================== PIPELINE STEPS =====================\n",
    "def pass1_geometry_classification(raster_stack, patch_size, stride, gdf, label_field, edge_bufs=None):\n",
    "    meta = []\n",
    "    sindex = gdf.sindex if len(gdf) else None\n",
    "    with rasterio.open(raster_stack[0]) as ref:\n",
    "        width, height = ref.width, ref.height\n",
    "        candidates = build_grid(width, height, patch_size, stride)\n",
    "        for (x, y) in candidates:\n",
    "            # Dynamic edge buffer check\n",
    "            if edge_bufs:\n",
    "                if x < edge_bufs[\"left\"] or y < edge_bufs[\"top\"] or \\\n",
    "                   (x + patch_size) > (width - edge_bufs[\"right\"]) or \\\n",
    "                   (y + patch_size) > (height - edge_bufs[\"bottom\"]):\n",
    "                    continue\n",
    "\n",
    "            win = Window(x, y, patch_size, patch_size)\n",
    "            if not window_has_data(ref, win):  # skip no-data / black tiles\n",
    "                continue\n",
    "            left, bottom, right, top = window_bbox(ref, win)\n",
    "            bbox_poly = box(left, bottom, right, top)\n",
    "            label, frac = classify_overlap_label(\n",
    "                bbox_poly, gdf, sindex, min_cover_frac=MIN_COVER_FRAC\n",
    "            )\n",
    "            meta.append({\n",
    "                \"x\": x, \"y\": y,\n",
    "                \"left\": left, \"bottom\": bottom, \"right\": right, \"top\": top,\n",
    "                \"frac\": frac,\n",
    "                \"label\": label\n",
    "            })\n",
    "    return meta\n",
    "\n",
    "\n",
    "def pass2_read_and_save_block_datasets(\n",
    "    raster_stack,\n",
    "    ref_profile,\n",
    "    meta,\n",
    "    block_groups: dict[int, list[int]],\n",
    "    out_root: Path,\n",
    "    save_format: str,\n",
    "    min_valid: float,\n",
    "    patch_size: int,\n",
    "    png_scale_per_patch: bool,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save patches grouped by block-id into:\n",
    "\n",
    "      OUT_ROOT/\n",
    "        dataset_0000/\n",
    "          High Risk/*.png|*.npy\n",
    "          No Risk/*.png|*.npy\n",
    "        dataset_0001/\n",
    "          ...\n",
    "\n",
    "    The 'set' column in the CSV will contain the dataset name (e.g. 'dataset_0000').\n",
    "    \"\"\"\n",
    "    out_root = Path(out_root)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    counters = defaultdict(int)\n",
    "    csv_path = out_root / \"labels_master.csv\"\n",
    "\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        write_csv_header(writer)\n",
    "\n",
    "        rgb_name = Path(raster_stack[0]).name\n",
    "        ndvi_name = Path(raster_stack[1]).name if len(raster_stack) > 1 else \"\"\n",
    "\n",
    "        with rasterio.open(raster_stack[0]) as ref:\n",
    "            for block_id, idxs in block_groups.items():\n",
    "                dataset_name = f\"dataset_{block_id:04d}\"\n",
    "\n",
    "                # ensure label dirs exist for this dataset\n",
    "                labels_in_block = sorted({meta[i][\"label\"] for i in idxs})\n",
    "                for lab in labels_in_block:\n",
    "                    (out_root / dataset_name / lab).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                for i in idxs:\n",
    "                    m = meta[i]\n",
    "                    x, y, label = m[\"x\"], m[\"y\"], m[\"label\"]\n",
    "\n",
    "                    # safety: skip if patch would go out of raster bounds\n",
    "                    if (x + patch_size) > ref.width or (y + patch_size) > ref.height:\n",
    "                        continue\n",
    "\n",
    "                    win = Window(x, y, patch_size, patch_size)\n",
    "                    stacked, valid_mask = read_window_stack_aligned(raster_stack, win, ref_profile)\n",
    "\n",
    "                    if not valid_mask.any():\n",
    "                        continue\n",
    "                    if valid_mask.mean() < min_valid:\n",
    "                        continue\n",
    "\n",
    "                    img_hwc = np.transpose(stacked, (1, 2, 0))  # (H,W,C)\n",
    "\n",
    "                    idx_out = counters[(block_id, label)]\n",
    "                    base = out_root / dataset_name / label / f\"patch_{idx_out:06d}\"\n",
    "                    saved_name = save_patch_png_and_or_npy(\n",
    "                        base, img_hwc, save_format, png_scale_per_patch\n",
    "                    )\n",
    "\n",
    "                    writer.writerow(\n",
    "                        csv_row_for_meta(\n",
    "                            dataset_name,  # goes into 'set' column\n",
    "                            saved_name,\n",
    "                            m,\n",
    "                            patch_size,\n",
    "                            rgb_name,\n",
    "                            ndvi_name,\n",
    "                        )\n",
    "                    )\n",
    "                    counters[(block_id, label)] += 1\n",
    "\n",
    "    print(f\"Master CSV: {csv_path}\")\n",
    "    return counters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63424fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    validate_config()\n",
    "    out_root = Path(OUT_ROOT)\n",
    "\n",
    "    ref_profile = load_reference_profile(RGB_PATH)\n",
    "    gdf = load_annotations(GEOJSON, target_crs=ref_profile[\"crs\"])\n",
    "    assert_gdf(gdf)\n",
    "\n",
    "    edge_bufs = compute_edges_95(\n",
    "        RGB_PATH,\n",
    "        frac=EDGE_FRAC,\n",
    "        black_thr=BLACK_THRESHOLD,\n",
    "        use_bands=3,\n",
    "    )\n",
    "    log(f\"Dynamic edge buffers: {edge_bufs}\")\n",
    "\n",
    "    meta = pass1_geometry_classification(\n",
    "        RASTER_STACK,\n",
    "        PATCH_SIZE,\n",
    "        STRIDE,\n",
    "        gdf,\n",
    "        LABEL_FIELD,\n",
    "        edge_bufs=edge_bufs,\n",
    "    )\n",
    "    log(f\"Pass1 produced {len(meta)} candidate patches.\")\n",
    "\n",
    "    block_groups, unique_groups, meta_kept = group_into_blocks(\n",
    "        meta,\n",
    "        block_size=BLOCK_SIZE,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        stride=STRIDE,\n",
    "        apply_margin_filter=True,\n",
    "    )\n",
    "\n",
    "    pass2_read_and_save_block_datasets(\n",
    "        RASTER_STACK,\n",
    "        ref_profile,\n",
    "        meta_kept,\n",
    "        block_groups,\n",
    "        out_root,\n",
    "        SAVE_FORMAT,\n",
    "        MIN_VALID,\n",
    "        PATCH_SIZE,\n",
    "        PNG_SCALE_PER_PATCH,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b29c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
